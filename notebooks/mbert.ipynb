{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a1fc24",
   "metadata": {},
   "source": [
    "#### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b2bd08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from spellchecker import SpellChecker\n",
    "import spacy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab310897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mbchavez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec615da",
   "metadata": {},
   "source": [
    "#### Setting up Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "014e1d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "      <th>is_ne</th>\n",
       "      <th>is_spelling_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>Gusto</td>\n",
       "      <td>FIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>kong</td>\n",
       "      <td>FIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>intindihin</td>\n",
       "      <td>FIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>pero</td>\n",
       "      <td>FIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>hindi</td>\n",
       "      <td>FIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_id  sentence_id        word label is_ne  is_spelling_correct\n",
       "0       45            1       Gusto   FIL   NaN                 True\n",
       "1       46            1        kong   FIL   NaN                 True\n",
       "2       47            1  intindihin   FIL   NaN                 True\n",
       "3       48            1        pero   FIL   NaN                 True\n",
       "4       49            1       hindi   FIL   NaN                 True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dataset: \")\n",
    "language = pd.read_csv(\"../data/final_annotations.csv\")\n",
    "\n",
    "language.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "457efac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_id                    0\n",
       "sentence_id                0\n",
       "word                      16\n",
       "label                      0\n",
       "is_ne                  21454\n",
       "is_spelling_correct        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Empty Tokens\n",
    "language.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "692f82d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_id                    0\n",
       "sentence_id                0\n",
       "word                       0\n",
       "label                      0\n",
       "is_ne                  21438\n",
       "is_spelling_correct        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Empty Tokens \n",
    "language = language.dropna(subset=['word'])\n",
    "language.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dad03a",
   "metadata": {},
   "source": [
    "#### Join Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02334b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "      <th>is_ne</th>\n",
       "      <th>is_spelling_correct</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>Gusto</td>\n",
       "      <td>FIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Gusto kong intindihin pero hindi ko maintindih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>kong</td>\n",
       "      <td>FIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Gusto kong intindihin pero hindi ko maintindih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>intindihin</td>\n",
       "      <td>FIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Gusto kong intindihin pero hindi ko maintindih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>pero</td>\n",
       "      <td>FIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Gusto kong intindihin pero hindi ko maintindih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>hindi</td>\n",
       "      <td>FIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Gusto kong intindihin pero hindi ko maintindih...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_id  sentence_id        word label is_ne  is_spelling_correct  \\\n",
       "0       45            1       Gusto   FIL   NaN                 True   \n",
       "1       46            1        kong   FIL   NaN                 True   \n",
       "2       47            1  intindihin   FIL   NaN                 True   \n",
       "3       48            1        pero   FIL   NaN                 True   \n",
       "4       49            1       hindi   FIL   NaN                 True   \n",
       "\n",
       "                                            sentence  \n",
       "0  Gusto kong intindihin pero hindi ko maintindih...  \n",
       "1  Gusto kong intindihin pero hindi ko maintindih...  \n",
       "2  Gusto kong intindihin pero hindi ko maintindih...  \n",
       "3  Gusto kong intindihin pero hindi ko maintindih...  \n",
       "4  Gusto kong intindihin pero hindi ko maintindih...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure words are strings\n",
    "language[\"word\"] = language[\"word\"].astype(str)\n",
    "\n",
    "# Group by sentence_id and combine words\n",
    "sentences = language.groupby(\"sentence_id\")[\"word\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# Map the combined sentence back to the original dataframe\n",
    "language[\"sentence\"] = language[\"sentence_id\"].map(sentences)\n",
    "\n",
    "\n",
    "language.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07e067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: label_id, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map Labels to Numbers\n",
    "label_map = {label: idx for idx, label in enumerate(language['label'].unique())}\n",
    "language[\"label_id\"] = language['label'].map(label_map)\n",
    "\n",
    "language[\"label_id\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52340e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "      <th>label_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Gusto, kong, intindihin, pero, hindi, ko, mai...</td>\n",
       "      <td>[FIL, FIL, FIL, FIL, FIL, FIL, FIL, OTH, FIL, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Kaya, kayong, mga, babae, wag, kayong, basta,...</td>\n",
       "      <td>[FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[Kasalan, naman, nila, bakit, hindi, nila, sin...</td>\n",
       "      <td>[FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[At, sila-sila, rin, ang, umuunlad, ?]</td>\n",
       "      <td>[FIL, FIL, FIL, FIL, FIL, OTH]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Nakakamiss, ung, mga, gantong, content, ni, k...</td>\n",
       "      <td>[FIL, FIL, FIL, FIL, ENG, FIL, FIL, OTH, OTH]</td>\n",
       "      <td>[0, 0, 0, 0, 2, 0, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>2601</td>\n",
       "      <td>[Wala, naman, po, akong, nararamdamang, sintom...</td>\n",
       "      <td>[FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, OTH]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>2602</td>\n",
       "      <td>[Mabigat, na, rin, naman, ang, nabubuhat, ko, .]</td>\n",
       "      <td>[FIL, FIL, FIL, FIL, FIL, FIL, FIL, OTH]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>2603</td>\n",
       "      <td>[Sana, hindi, po, hindi, masarap, ulam, nila, ...</td>\n",
       "      <td>[FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>2604</td>\n",
       "      <td>[Hello, po, mag, ask, po, ako, sa, inyo, ng, h...</td>\n",
       "      <td>[ENG, FIL, FIL, ENG, FIL, FIL, FIL, FIL, FIL, ...</td>\n",
       "      <td>[2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>2605</td>\n",
       "      <td>[Sila, rin, ay, tapat, kay, Jehova, ,, at, wal...</td>\n",
       "      <td>[FIL, FIL, FIL, FIL, FIL, OTH, OTH, FIL, FIL, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1310 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id                                              words  \\\n",
       "0               1  [Gusto, kong, intindihin, pero, hindi, ko, mai...   \n",
       "1               2  [Kaya, kayong, mga, babae, wag, kayong, basta,...   \n",
       "2               3  [Kasalan, naman, nila, bakit, hindi, nila, sin...   \n",
       "3               4             [At, sila-sila, rin, ang, umuunlad, ?]   \n",
       "4               5  [Nakakamiss, ung, mga, gantong, content, ni, k...   \n",
       "...           ...                                                ...   \n",
       "1305         2601  [Wala, naman, po, akong, nararamdamang, sintom...   \n",
       "1306         2602   [Mabigat, na, rin, naman, ang, nabubuhat, ko, .]   \n",
       "1307         2603  [Sana, hindi, po, hindi, masarap, ulam, nila, ...   \n",
       "1308         2604  [Hello, po, mag, ask, po, ako, sa, inyo, ng, h...   \n",
       "1309         2605  [Sila, rin, ay, tapat, kay, Jehova, ,, at, wal...   \n",
       "\n",
       "                                                 labels  \\\n",
       "0     [FIL, FIL, FIL, FIL, FIL, FIL, FIL, OTH, FIL, ...   \n",
       "1     [FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, ...   \n",
       "2     [FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, ...   \n",
       "3                        [FIL, FIL, FIL, FIL, FIL, OTH]   \n",
       "4         [FIL, FIL, FIL, FIL, ENG, FIL, FIL, OTH, OTH]   \n",
       "...                                                 ...   \n",
       "1305      [FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, OTH]   \n",
       "1306           [FIL, FIL, FIL, FIL, FIL, FIL, FIL, OTH]   \n",
       "1307  [FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, FIL, ...   \n",
       "1308  [ENG, FIL, FIL, ENG, FIL, FIL, FIL, FIL, FIL, ...   \n",
       "1309  [FIL, FIL, FIL, FIL, FIL, OTH, OTH, FIL, FIL, ...   \n",
       "\n",
       "                                              label_ids  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, ...  \n",
       "1            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "2                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "3                                    [0, 0, 0, 0, 0, 1]  \n",
       "4                           [0, 0, 0, 0, 2, 0, 0, 1, 1]  \n",
       "...                                                 ...  \n",
       "1305                        [0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "1306                           [0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "1307  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1308  [2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, ...  \n",
       "1309  [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[1310 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group Sentences, Labels to one Dataframe\n",
    "sentences = language.groupby(\"sentence_id\")['word'].apply(list).tolist()\n",
    "labels = language.groupby(\"sentence_id\")['label'].apply(list).tolist()\n",
    "label_ids = language.groupby(\"sentence_id\")['label_id'].apply(list).tolist()  \n",
    "\n",
    "sentences_df = pd.DataFrame({\n",
    "    \"sentence_id\": language['sentence_id'].unique(),\n",
    "    \"words\": sentences,\n",
    "    \"labels\": labels,\n",
    "    \"label_ids\": label_ids\n",
    "})\n",
    "\n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29680a6",
   "metadata": {},
   "source": [
    "#### Load BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73498f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbert = \"bert-base-multilingual-cased\"\n",
    "\n",
    "# Fast tokenizer for word_ids()\n",
    "mbert_tokenizer = BertTokenizerFast.from_pretrained(mbert)\n",
    "\n",
    "# Token classification model with 3 labels: FIL=0, OTH=1, ENG=2\n",
    "mbert_model = BertForTokenClassification.from_pretrained(mbert, num_labels=3)\n",
    "mbert_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f1a6568",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_inputs = mbert_tokenizer(sentences,is_split_into_words=True,return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "aligned_labels = []\n",
    "\n",
    "for i, label in enumerate(label_ids):\n",
    "    word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "    aligned_label = []\n",
    "\n",
    "    for word_id in word_ids:\n",
    "        if word_id is None:\n",
    "            aligned_label.append(-100)\n",
    "        else:\n",
    "            aligned_label.append(label[word_id])\n",
    "    aligned_labels.append(aligned_label)\n",
    "\n",
    "tokenized_inputs[\"labels\"] = torch.tensor(aligned_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pinoybotenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
